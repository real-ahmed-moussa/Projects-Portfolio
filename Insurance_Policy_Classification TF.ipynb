{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Policy Binary Classification - TensorFlow CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Load and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Dataset\n",
    "data = pd.read_csv(\"TrainingDataset_2023Qualification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Features and Target Variables\n",
    "features = data.iloc[:, 2:]\n",
    "target = data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into Training, Validation, and Testing Sets\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(features, target, test_size=0.20)\n",
    "\n",
    "# Split the Data into Training and Validation Sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.1] Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "x_train.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Numerical Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Numerical Continuous Variables for Anomalies [Outliers]\n",
    "x_train[[\"policyHolderAge\", \"homeInsurancePremium\", \"nbWeeksInsured\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Histogram of the Numerical Variables\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].hist(x_train[\"policyHolderAge\"], bins=20, color='blue')\n",
    "ax[0].set_title('policyHolderAge')\n",
    "ax[1].hist(x_train[\"homeInsurancePremium\"], bins=20, color='red')\n",
    "ax[1].set_title('homeInsurancePremium')\n",
    "ax[2].hist(x_train[\"nbWeeksInsured\"], bins=20, color='green')\n",
    "ax[2].set_title('nbWeeksInsured')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Scatterplot of the Numerical Variables\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].scatter(x_train[\"policyHolderAge\"], x_train[\"homeInsurancePremium\"], color='blue')\n",
    "ax[0].set_title('policyHolderAge vs. homeInsurancePremium')\n",
    "ax[1].scatter(x_train[\"policyHolderAge\"], x_train[\"nbWeeksInsured\"], color='red')\n",
    "ax[1].set_title('policyHolderAge vs. nbWeeksInsured')\n",
    "ax[2].scatter(x_train[\"homeInsurancePremium\"], x_train[\"nbWeeksInsured\"], color='green')\n",
    "ax[2].set_title('homeInsurancePremium vs. nbWeeksInsured')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Outliers for homeInsurancePremium\n",
    "\"\"\" Outliers do exist within the homeInsurancePremium variable. However, having more than one outlier means they did not come by mistake. Hence, they will be kept but with caution. \"\"\"\n",
    "mask = x_train[\"homeInsurancePremium\"] > 4000\n",
    "print(mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Colinearity\n",
    "x_train[[\"policyHolderAge\", \"homeInsurancePremium\", \"nbWeeksInsured\"]].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Categorical Variables - High Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can use: frequency encoding, target encoding, hashing trick encoding, or embeding\n",
    "# Check the Number of Distinct Values - Variables are already Label Encoded!\n",
    "x_train[[\"territory\", \"saleChannel\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Histogram of the Variables\n",
    "ig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].hist(x_train[\"territory\"], bins=20, color='blue')\n",
    "ax[0].set_title('territory')\n",
    "ax[1].hist(x_train[\"saleChannel\"], bins=20, color='red')\n",
    "ax[1].set_title('saleChannel')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Categorical Dependence\n",
    "# Comment: Some p-values are zero which indicates there is a relationship between their corresponding variables.\n",
    "#          A low p-value doesn't necessarily mean the relationship is strong, and it doesn't provide information about the nature or strength of the relationship.\n",
    "#          In addition, a low p-value could also mean that the sample size is large enough to detect even small differences between observed and expected frequencies.\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(index=x_train[\"territory\"], columns=x_train[\"saleChannel\"])\n",
    "stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-square Statistic is: \" + str(stat))\n",
    "print(\"p-value is: \" + str(p))\n",
    "print(\"Number of DOFs is: \" + str(dof))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Categorical Variables - Low Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Frequencies of Categorical Variables\n",
    "print(x_train[[\"Gender\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"hasCanadianDrivingLicense\" ]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"hasAutoInsurance\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"hadVehicleClaimInPast\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"isOwner\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"rentedVehicle\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"hasMortgage\"]].value_counts())\n",
    "print(\"---------\")\n",
    "print(x_train[[\"vehicleStatus\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Histogram of the Variables\n",
    "columns = ['Gender', 'hasCanadianDrivingLicense', \"hasAutoInsurance\", \"hadVehicleClaimInPast\", \"isOwner\", \"rentedVehicle\", \"hasMortgage\", \"vehicleStatus\"]\n",
    "\n",
    "# set the number of rows and columns for the subplot\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "# create the subplot grid\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(16, 8))\n",
    "\n",
    "# loop through the columns and axes\n",
    "for i, col in enumerate(columns):\n",
    "    # calculate the frequency of each category in the column\n",
    "    freq = x_train[col].value_counts()\n",
    "    \n",
    "    # get the axis for the subplot\n",
    "    axi = ax.flat[i]\n",
    "    \n",
    "    # plot the frequency as a bar chart\n",
    "    freq.plot(kind='bar', ax=axi)\n",
    "    axi.set_title(col)\n",
    "    axi.set_xlabel(col)\n",
    "    axi.set_ylabel('Frequency')\n",
    "\n",
    "# adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Dependence\n",
    "# [1] Establish contingency tables\n",
    "# [2] Perform Chi-squared test\n",
    "# [3] Comment: Some p-values are zero which indicates there is a relationship between their corresponding variables.\n",
    "#              A low p-value doesn't necessarily mean the relationship is strong, and it doesn't provide information about the nature or strength of the relationship.\n",
    "#              In addition, a low p-value could also mean that the sample size is large enough to detect even small differences between observed and expected frequencies.\n",
    "#              Proceed with caution!\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "p_matrix = -1 * np.ones((len(columns), len(columns)))\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i+1, len(columns)):\n",
    "        \n",
    "        contingency_table = pd.crosstab(index=x_train[columns[i]], columns=x_train[columns[j]])\n",
    "        stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        p_matrix[i, j] = np.round(p, 5)\n",
    "        \n",
    "print(p_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Response Variable for Class Imbalance\n",
    "target_imbalance = (y_train.value_counts()/x_train.shape[0])\n",
    "target_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Classes\n",
    "frequency = y_train.value_counts()\n",
    "\n",
    "# Plot the frequency using a bar plot\n",
    "frequency.plot(kind='bar')\n",
    "\n",
    "# Add labels to the x and y axes\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.2] Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA Values in \"hasMortgage\" means the house is rented. Hence, it needs to be imputed as a thid category!\n",
    "x_train.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3] Data Pre-processing Pipelines\n",
    "Create a set of data preprocessing pipelines before building the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Columns Lists\n",
    "num_features = [\"policyHolderAge\", \"homeInsurancePremium\", \"nbWeeksInsured\"]\n",
    "cat_long_features = [\"territory\", \"saleChannel\"]\n",
    "cat_features = ['Gender', 'hasCanadianDrivingLicense', \"hasAutoInsurance\", \"hadVehicleClaimInPast\", \"isOwner\", \"rentedVehicle\", \"hasMortgage\", \"vehicleStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer #1\n",
    "Imputation + Categorical Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_and_onehot_pipe = Pipeline(steps=[\n",
    "                                            ('imputer', SimpleImputer(strategy='constant', fill_value=2)),\n",
    "                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                        ])\n",
    "\n",
    "\n",
    "preprocessing_transformer1 = ColumnTransformer(transformers=[\n",
    "                                                                ('genderPipe', OneHotEncoder(handle_unknown='ignore'), [\"Gender\"]),\n",
    "                                                                ('vehicleClaimPipe', OneHotEncoder(handle_unknown='ignore'), [\"hadVehicleClaimInPast\"]),\n",
    "                                                                ('hasMortgagePipe', impute_and_onehot_pipe, [\"hasMortgage\"]),\n",
    "                                                                ('vehicleStatusPipe', OneHotEncoder(handle_unknown='ignore'), [\"vehicleStatus\"])\n",
    "                                                            ], remainder='passthrough')\n",
    "\n",
    "preprocessing_pipeline1 = Pipeline([\n",
    "                                      ('transform_column', preprocessing_transformer1)\n",
    "                                   ])\n",
    "preprocessing_pipeline1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer #3\n",
    "Imputation + Categorical Encodings + Numeric Standardization + Normalization (cat_long_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "impute_and_onehot_pipe = Pipeline(steps=[\n",
    "                                            ('imputer', SimpleImputer(strategy='constant', fill_value=2)),\n",
    "                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                        ])\n",
    "\n",
    "\n",
    "preprocessing_transformer3 = ColumnTransformer(transformers=[\n",
    "                                                                (\"numericPipe_log\", FunctionTransformer(np.log, validate=True), [\"policyHolderAge\", \"homeInsurancePremium\"]),\n",
    "                                                                (\"numericPipe\", StandardScaler(), num_features),\n",
    "                                                                (\"catLongPipe\", StandardScaler(), cat_long_features),\n",
    "                                                                ('genderPipe', OneHotEncoder(handle_unknown='ignore'), [\"Gender\"]),\n",
    "                                                                ('vehicleClaimPipe', OneHotEncoder(handle_unknown='ignore'), [\"hadVehicleClaimInPast\"]),\n",
    "                                                                ('hasMortgagePipe', impute_and_onehot_pipe, [\"hasMortgage\"]),\n",
    "                                                                ('vehicleStatusPipe', OneHotEncoder(handle_unknown='ignore'), [\"vehicleStatus\"]),\n",
    "                                                            ], remainder='passthrough')\n",
    "\n",
    "preprocessing_pipeline3 = Pipeline([\n",
    "                                      ('transform_column', preprocessing_transformer3)\n",
    "                                   ])\n",
    "preprocessing_pipeline3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer #5\n",
    "Imputation + Categorical Encodings + Numeric Standardization + Count Encoding (cat_long_features) + Normalization (cat_long_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "impute_and_onehot_pipe = Pipeline(steps=[\n",
    "                                            ('imputer', SimpleImputer(strategy='constant', fill_value=2)),\n",
    "                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                        ])\n",
    "\n",
    "\n",
    "preprocessing_transformer5 = ColumnTransformer(transformers=[\n",
    "                                                                (\"numericPipe_log\", FunctionTransformer(np.log, validate=True), [\"policyHolderAge\", \"homeInsurancePremium\"]),\n",
    "                                                                (\"numericPipe\", StandardScaler(), num_features),\n",
    "                                                                (\"catLongPipe\", StandardScaler(), cat_long_features),\n",
    "                                                                ('genderPipe', OneHotEncoder(handle_unknown='ignore'), [\"Gender\"]),\n",
    "                                                                ('vehicleClaimPipe', OneHotEncoder(handle_unknown='ignore'), [\"hadVehicleClaimInPast\"]),\n",
    "                                                                ('hasMortgagePipe', impute_and_onehot_pipe, [\"hasMortgage\"]),\n",
    "                                                                ('vehicleStatusPipe', OneHotEncoder(handle_unknown='ignore'), [\"vehicleStatus\"]),\n",
    "                                                              ], remainder='passthrough')\n",
    "\n",
    "preprocessing_pipeline5 = Pipeline([\n",
    "                                        (\"terr_Encoder\", ce.CountEncoder(cols=[\"territory\"], return_df=True)),\n",
    "                                        (\"saleChannel_Encoder\", ce.CountEncoder(cols=[\"saleChannel\"], return_df=True)),\n",
    "                                        ('transform_column', preprocessing_transformer5)\n",
    "                                   ])\n",
    "\n",
    "preprocessing_pipeline5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer #7\n",
    "Imputation + Categorical Encodings + Numeric Standardization + Target Encoding (cat_long_features) + Normalization (cat_long_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "impute_and_onehot_pipe = Pipeline(steps=[\n",
    "                                            ('imputer', SimpleImputer(strategy='constant', fill_value=2)),\n",
    "                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                        ])\n",
    "\n",
    "\n",
    "preprocessing_transformer7 = ColumnTransformer(transformers=[\n",
    "                                                                (\"numericPipe_log\", FunctionTransformer(np.log, validate=True), [\"policyHolderAge\", \"homeInsurancePremium\"]),\n",
    "                                                                (\"numericPipe\", StandardScaler(), num_features),\n",
    "                                                                (\"catLongPipe\", StandardScaler(), cat_long_features),\n",
    "                                                                ('genderPipe', OneHotEncoder(handle_unknown='ignore'), [\"Gender\"]),\n",
    "                                                                ('vehicleClaimPipe', OneHotEncoder(handle_unknown='ignore'), [\"hadVehicleClaimInPast\"]),\n",
    "                                                                ('hasMortgagePipe', impute_and_onehot_pipe, [\"hasMortgage\"]),\n",
    "                                                                ('vehicleStatusPipe', OneHotEncoder(handle_unknown='ignore'), [\"vehicleStatus\"]),\n",
    "                                                              ], remainder='passthrough')\n",
    "\n",
    "preprocessing_pipeline7 = Pipeline([\n",
    "                                        (\"terr_Encoder\", ce.TargetEncoder(cols=[\"territory\"], return_df=True)),\n",
    "                                        (\"saleChannel_Encoder\", ce.TargetEncoder(cols=[\"saleChannel\"], return_df=True)),\n",
    "                                        ('transform_column', preprocessing_transformer7)\n",
    "                                   ])\n",
    "\n",
    "preprocessing_pipeline7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Data\n",
    "x_train_trans = preprocessing_pipeline5.fit_transform(x_train)\n",
    "x_val_trans = preprocessing_pipeline5.fit_transform(x_val)\n",
    "x_test_trans = preprocessing_pipeline5.fit_transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.1] Model Metrics & Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "              keras.metrics.TruePositives(name='tp'),\n",
    "              keras.metrics.FalsePositives(name='fp'),\n",
    "              keras.metrics.TrueNegatives(name='tn'),\n",
    "              keras.metrics.FalseNegatives(name='fn'), \n",
    "              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "              keras.metrics.Precision(name='precision'),\n",
    "              keras.metrics.Recall(name='recall'),\n",
    "              keras.metrics.AUC(name='auc'),\n",
    "              keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "        ]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "  \n",
    "  # Try different CNN architectures!\n",
    "  model = keras.Sequential([\n",
    "                              keras.layers.Dense(19, activation='relu', input_shape=(x_train_trans.shape[-1],)),\n",
    "      \n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "      \n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    "                              keras.layers.Dense(250, activation='relu'),\n",
    " \n",
    "                              keras.layers.Dropout(0.50),\n",
    "                              keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "                          ])\n",
    "\n",
    "  model.compile(\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics\n",
    "              )\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.2] Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                    monitor='val_prc', \n",
    "                                                    verbose=1,\n",
    "                                                    patience=10,\n",
    "                                                    mode='max',\n",
    "                                                    restore_best_weights=True\n",
    "                                                )\n",
    "\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "model.predict(x_train_trans[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Losses\n",
    "results = model.evaluate(x_train_trans, y_train, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Correct for Initial Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(target)\n",
    "total = neg + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the Model with the New Initial Bias\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(x_train_trans[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Initial Loss\n",
    "results = model.evaluate(x_train_trans, y_train, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0])) # Loss Reduced Dramatically from 0.8197 to 0.3730!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Save Initial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Confirm Initial Bias Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Bias Model\n",
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "                                x_train_trans,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=20,\n",
    "                                validation_data=(x_val_trans, y_val), \n",
    "                                verbose=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biased Model\n",
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "                                    x_train_trans,\n",
    "                                    y_train,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    epochs=20,\n",
    "                                    validation_data=(x_val_trans, y_val), \n",
    "                                    verbose=0\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Results\n",
    "def plot_loss(history, label, color):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'], color=color, label='Train ' + label)\n",
    "    \n",
    "  plt.semilogy(history.epoch, history.history['val_loss'], color=color, label='Val ' + label, linestyle=\"--\")\n",
    "\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title(\"Loss vs. # of Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(zero_bias_history, \"Zero Bias\", \"blue\")\n",
    "plot_loss(careful_bias_history, \"Careful Bias\", \"green\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "baseline_history = model.fit(\n",
    "                                x_train_trans,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(x_val_trans, y_val)\n",
    "                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    \n",
    "    plt.plot(history.epoch, history.history[metric], color=\"blue\", label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric], color=\"blue\", linestyle=\"--\", label='Val')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Evaluate the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(x_train_trans, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(x_test_trans, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('No Buy Detected (True Negatives): ', cm[0][0])\n",
    "  print('No Buy Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Buy Missed (False Negatives): ', cm[1][0])\n",
    "  print('Buy Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Buy Decisions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(x_test_trans, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_baseline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([0,100])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"green\")\n",
    "plot_roc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"green\", linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.9 Plot AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"orange\")\n",
    "plot_prc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"blue\", linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.3] Class Weights Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Evaluate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Train Model - Consider Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "                                        x_train_trans,\n",
    "                                        y_train,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        epochs=EPOCHS,\n",
    "                                        callbacks=[early_stopping],\n",
    "                                        validation_data=(x_val_trans, y_val),\n",
    "                                        # The class weights go here\n",
    "                                        class_weight=class_weight\n",
    "                                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_weighted = weighted_model.predict(x_train_trans, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(x_test_trans, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(x_test_trans, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"blue\")\n",
    "plot_roc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"blue\", linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", y_train, train_predictions_weighted, color=\"orange\")\n",
    "plot_roc(\"Test Weighted\", y_test, test_predictions_weighted, color=\"orange\", linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.6 Plot AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"blue\")\n",
    "plot_prc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"blue\", linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Weighted\", y_train, train_predictions_weighted, color=\"green\")\n",
    "plot_prc(\"Test Weighted\", y_test, test_predictions_weighted, color=\"green\", linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.4] Over-sampling\n",
    "Correct for dataset response variable imbalance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Oversample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form np arrays of labels and features\n",
    "bool_train_labels = y_train != 0\n",
    "bool_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positive and negative features\n",
    "pos_features = x_train_trans[bool_train_labels]\n",
    "neg_features = x_train_trans[~bool_train_labels]\n",
    "\n",
    "pos_labels = y_train[bool_train_labels]\n",
    "neg_labels = y_train[~bool_train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Resampling\n",
    "BUFFER_SIZE = 100000\n",
    "\n",
    "def make_ds(features, labels):\n",
    "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
    "  return ds\n",
    "\n",
    "pos_ds = make_ds(pos_features, pos_labels)\n",
    "neg_ds = make_ds(neg_features, neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in pos_ds.take(1):\n",
    "  print(\"Features:\\n\", features.numpy())\n",
    "  print()\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Data\n",
    "resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
    "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in resampled_ds.take(1):\n",
    "  print(label.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Number of Steps per Epoch\n",
    "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
    "resampled_steps_per_epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Train Model - Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_model = make_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1] \n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val_trans, y_val)).cache()\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "                                            resampled_ds,\n",
    "                                            epochs=EPOCHS,\n",
    "                                            steps_per_epoch=resampled_steps_per_epoch,\n",
    "                                            callbacks=[early_stopping],\n",
    "                                            validation_data=val_ds\n",
    "                                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 Check Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(resampled_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4 Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_model = make_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1] \n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "                                            resampled_ds,\n",
    "                                            # These are not real epochs\n",
    "                                            steps_per_epoch=20,\n",
    "                                            epochs=10*EPOCHS,\n",
    "                                            callbacks=[early_stopping],\n",
    "                                            validation_data=(val_ds)\n",
    "                                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.5 Check Training History - Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(resampled_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.6 Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_resampled = resampled_model.predict(x_train_trans, batch_size=BATCH_SIZE)\n",
    "test_predictions_resampled = resampled_model.predict(x_test_trans, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_results = resampled_model.evaluate(x_test_trans, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.7 Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"blue\")\n",
    "plot_roc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"blue\", linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", y_train, train_predictions_weighted, color=\"orange\")\n",
    "plot_roc(\"Test Weighted\", y_test, test_predictions_weighted, color=\"orange\", linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Resampled\", y_train, train_predictions_resampled, color=\"green\")\n",
    "plot_roc(\"Test Resampled\", y_test, test_predictions_resampled, color=\"green\", linestyle='--')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.8 Plot AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", y_train, train_predictions_baseline, color=\"blue\")\n",
    "plot_prc(\"Test Baseline\", y_test, test_predictions_baseline, color=\"blue\", linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Weighted\", y_train, train_predictions_weighted, color=\"orange\")\n",
    "plot_prc(\"Test Weighted\", y_test, test_predictions_weighted, color=\"orange\", linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Resampled\", y_train, train_predictions_resampled, color=\"green\")\n",
    "plot_prc(\"Test Resampled\", y_test, test_predictions_resampled, color=\"green\", linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Scoring Dataset Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_comp = pd.read_csv(\"ScoringDataset_2023Qualification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Features\n",
    "x_comp = data_comp.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Data\n",
    "x_comp_trans = preprocessing_pipeline5.fit_transform(x_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Results\n",
    "test_predictions_weighted = weighted_model.predict(x_comp_trans, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# Convert probabilities into zeros and ones using the threshold value\n",
    "binary_predictions = np.where(test_predictions_weighted > threshold, 1, 0)\n",
    "\n",
    "# Print the binary predictions\n",
    "binary_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to DF\n",
    "pred_df = pd.DataFrame(binary_predictions)\n",
    "pred_df.to_csv('comp_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
